{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnoza raka piersi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from statsmodels.discrete.discrete_model import Logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.xlsx\")\n",
    "\n",
    "#Losowy podzial danych na zbiór treningowy (80%) i testowy (20%) \n",
    "train, test = model_selection.train_test_split(data,test_size = .20)\n",
    "\n",
    "#Podzial danych na zmienne zalezne i niezalezne\n",
    "xtrain = train.drop(columns=['Classification']).values\n",
    "ytrain = (train[\"Classification\"].values)-1\n",
    "xtest = test.drop(columns=['Classification']).values\n",
    "ytest = (test[\"Classification\"].values)-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uczenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.487707\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "model = Logit(ytrain, xtrain).fit()\n",
    "ypred = model.predict(xtest)\n",
    "cut_off = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wyliczanie trafnosci i czulosci dla progu odciecia 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trafnosc dla punktu odciecia (0,5): 0.7083333333333334\n",
      "Czulosc dla punktu odciecia (0,5): 0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "#Macierz bledu dla progu odciecia 0,5\n",
    "tn, fp, fn, tp = confusion_matrix(ytest,ypred >= cut_off).ravel()\n",
    "\n",
    "#Obliczanie trafnosci z macierzy bledu\n",
    "accuracy=((tp + tn)/(tn + fp + fn + tp))\n",
    "print ('Trafnosc dla punktu odciecia (0,5):', accuracy)\n",
    "\n",
    "#Obliczanie czulosci z macierzy bledu\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Czulosc dla punktu odciecia (0,5):', sensitivity )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definiowanie kosztów leczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_koszt = 48477\n",
    "tn_koszt = 0\n",
    "fp_koszt = 751\n",
    "fn_koszt = 89463"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testowanie nowych progow odciecia przy okreslonych kosztach leczenia\n",
    "Funkcja wyliczajaca najnizsze koszty leczenia oraz odpowiadajace im punkty odciecia  \n",
    "Dodatkowa indeksacia zostala dodana po to aby unkinac progu odciecia rownego 0, który  \n",
    "czasami powodował błedy w dalszej części zdania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00     638462\n",
      "0.01     638462\n",
      "0.02     638462\n",
      "0.03     637711\n",
      "0.04     637711\n",
      "         ...   \n",
      "0.96     999075\n",
      "0.97    1122033\n",
      "0.98    1122033\n",
      "0.99    1122033\n",
      "1.00    1163019\n",
      "Length: 101, dtype: int64\n",
      "Najnizszy koszt: 636960\n",
      "Punkt odciecia dla tego kosztu: 0.23\n"
     ]
    }
   ],
   "source": [
    "punkty_odciecia = np.arange(0, 1.01, 0.01)\n",
    "wyniki = {}\n",
    "for punkt in punkty_odciecia:\n",
    "    tn2, fp2, fn2, tp2 = confusion_matrix(ytest,ypred > punkt).ravel()\n",
    "    koszt = fn2 * fn_koszt + fp2 * fp_koszt + tn2 * tn_koszt +tp2 * tp_koszt\n",
    "    wyniki[punkt] = koszt\n",
    "\n",
    "wyniki = pd.Series(wyniki)\n",
    "print(wyniki)\n",
    "liczba_argumentow = wyniki.value_counts()[wyniki.iloc[wyniki.argmin()]]\n",
    "najnizszy_koszt = wyniki.iloc[wyniki.argmin()]\n",
    "najlepszy_punkt_odciecia = wyniki.iloc[wyniki.argmin():wyniki.argmin()+liczba_argumentow].index[liczba_argumentow-1]\n",
    "print('Najnizszy koszt:',najnizszy_koszt)\n",
    "print('Punkt odciecia dla tego kosztu:',najlepszy_punkt_odciecia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funkcja zwracajaca ostateczne wyniki po wprowadzeniu wybranego progu odciecia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def podsumowanie_modelu(punkt_odciecia):\n",
    "    tn, fp, fn, tp = confusion_matrix(ytest, ypred > punkt_odciecia).ravel()\n",
    "    specyficznosc = tn / (tn + fp)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    accuracy = (tp + tn)/ (tn + tp + fn + fp)\n",
    "    print('Raport klasyfikacji:\\n{}'.format(classification_report(ytest, ypred > punkt_odciecia)))\n",
    "    macierz_pomylek = pd.DataFrame(confusion_matrix(ytest, ypred > punkt_odciecia), \n",
    "             columns = ['predicted negatives', 'predicted positives'], \n",
    "             index = ['actual negatives', 'actual positives'])\n",
    "    print('\\nMacierz pomyłek:\\n{}'.format(macierz_pomylek))\n",
    "    print ('Trafnosc dla optymalnego punktu odciecia:', accuracy)\n",
    "    print('Czulosc dla optymalnego punktu odciecia:', sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podsumowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raport klasyfikacji:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.18      0.31        11\n",
      "           1       0.59      1.00      0.74        13\n",
      "\n",
      "    accuracy                           0.62        24\n",
      "   macro avg       0.80      0.59      0.53        24\n",
      "weighted avg       0.78      0.62      0.54        24\n",
      "\n",
      "\n",
      "Macierz pomyłek:\n",
      "                  predicted negatives  predicted positives\n",
      "actual negatives                    2                    9\n",
      "actual positives                    0                   13\n",
      "Trafnosc dla optymalnego punktu odciecia: 0.625\n",
      "Czulosc dla optymalnego punktu odciecia: 1.0\n"
     ]
    }
   ],
   "source": [
    "podsumowanie_modelu(najlepszy_punkt_odciecia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki koncowe są bardzo mocno zależne od tego jakie dane znajdą się w zbiorze testowym.\n",
    "Jednak niezaleznie od podzialu danych w kazdym przypadku otrzymamy czulosc rowna 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
